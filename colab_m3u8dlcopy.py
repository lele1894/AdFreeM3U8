#@title M3U8ä¸‹è½½-1.1
import os
import sys
import subprocess
import requests
import re
import json
import time
import shutil
from pathlib import Path
from urllib.parse import urlparse
from concurrent.futures import ThreadPoolExecutor, as_completed

def print_banner():
    """æ‰“å°ç¾åŒ–çš„æ¨ªå¹…"""
    print("\n" + "=" * 50)
    print("M3U8è§†é¢‘ä¸‹è½½åŠ©æ‰‹ v1.0")
    print("=" * 50)
    print("âœ¨ æ”¯æŒæ–­ç‚¹ç»­ä¼ ")
    print("âœ¨ è‡ªåŠ¨åˆå¹¶åˆ†ç‰‡")
    print("âœ¨ å¤šçº¿ç¨‹ä¸‹è½½åŠ é€Ÿ")
    print("âœ¨ è‡ªåŠ¨å»é™¤å¹¿å‘Š")
    print("=" * 50 + "\n")

def print_step(step, message):
    """æ‰“å°å¸¦æœ‰æ­¥éª¤çš„æ¶ˆæ¯"""
    print(f"[{step}] {message}")

def check_ffmpeg():
    """æ£€æŸ¥ffmpegæ˜¯å¦å·²å®‰è£…"""
    try:
        result = subprocess.run(["ffmpeg", "-version"], capture_output=True, text=True)
        return result.returncode == 0
    except:
        return False

def install_dependencies():
    """å®‰è£…ä¾èµ–"""
    try:
        print_step("â¬", "æ£€æŸ¥ä¾èµ–...")
        if check_ffmpeg():
            print_step("ffmpegå·²å®‰è£…ï¼Œè·³è¿‡å®‰è£…æ­¥éª¤")
            return True
            
        print_step("â¬", "æ­£åœ¨å®‰è£…ffmpeg...")
        # åªéœ€è¦å®‰è£…ffmpeg
        subprocess.run(["apt-get", "update", "-qq"], capture_output=True)
        subprocess.run(["apt-get", "install", "-y", "ffmpeg"], capture_output=True)
        print_step("ä¾èµ–å®‰è£…æˆåŠŸ!")
        return True
    except Exception as e:
        print_step("âŒ", f"ä¾èµ–å®‰è£…å¤±è´¥: {str(e)}")
        return False

def analyze_m3u8(url):
    """åˆ†æm3u8æ–‡ä»¶ï¼Œæ‰¾å‡ºå¹¿å‘Šç‰‡æ®µå’Œåˆ†ç‰‡URL"""
    try:
        print_step("ğŸ”", "åˆ†æm3u8å†…å®¹...")
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': '*/*',
            'Accept-Language': 'en-US,en;q=0.9',
            'Origin': 'https://vod.mycamtv.net',
            'Referer': 'https://vod.mycamtv.net/',
            'Sec-Fetch-Dest': 'empty',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Site': 'same-origin',
            'Connection': 'keep-alive'
        }
        response = requests.get(url, headers=headers, timeout=10)
        content = response.text
        base_url = '/'.join(url.split('/')[:-1]) + '/'
        
        # æŸ¥æ‰¾æ‰€æœ‰åˆ†ç‰‡å’Œæ—¶é•¿
        segments = []
        total_duration = 0
        is_ad_segment = False
        duration = 0
        
        for line in content.split('\n'):
            if line.startswith('#EXTINF:'):
                duration = float(line.split(':')[1].split(',')[0])
            elif line.startswith('#EXT-X-DISCONTINUITY'):
                if duration > 0:
                    segments.append({
                        'start': total_duration,
                        'duration': duration,
                        'is_ad': is_ad_segment
                    })
                    total_duration += duration
                is_ad_segment = not is_ad_segment
            elif line.endswith('.ts') or line.endswith('.jpeg'):
                if not line.startswith('http'):
                    line = base_url + line
                if 'redtraffic' in line:
                    is_ad_segment = True
                segments.append({
                    'start': total_duration,
                    'duration': duration,
                    'is_ad': is_ad_segment,
                    'url': line
                })
                total_duration += duration
                duration = 0
        
        # è®¡ç®—å¹¿å‘Šå’Œè§†é¢‘æ—¶é•¿
        ad_duration = sum(s['duration'] for s in segments if s['is_ad'])
        video_duration = sum(s['duration'] for s in segments if not s['is_ad'])
        
        print_step(f"è§†é¢‘æ€»é•¿: {video_duration:.1f}ç§’")
        print_step(f"å¹¿å‘Šæ—¶é•¿: {ad_duration:.1f}ç§’")
        
        # è¿”å›éå¹¿å‘Šç‰‡æ®µ
        non_ad_segments = [s for s in segments if not s['is_ad']]
        print_step(f"æ€»ç‰‡æ®µæ•°: {len(non_ad_segments)}")
        return non_ad_segments
        
    except Exception as e:
        print_step("âš ï¸", f"åˆ†æå¤±è´¥: {str(e)}")
        return None

def download_segment(seg_info):
    """ä¸‹è½½å•ä¸ªåˆ†ç‰‡ï¼Œæ”¯æŒé‡è¯•"""
    seg_path, url, index, total = seg_info
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': '*/*',
        'Accept-Language': 'en-US,en;q=0.9',
        'Origin': 'https://vod.mycamtv.net',
        'Referer': 'https://vod.mycamtv.net/',
        'Sec-Fetch-Dest': 'empty',
        'Sec-Fetch-Mode': 'cors',
        'Sec-Fetch-Site': 'same-origin',
        'Connection': 'keep-alive'
    }
    
    for retry in range(3):
        try:
            response = requests.get(url, headers=headers, timeout=30, stream=True)
            if response.status_code == 200:
                with open(seg_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                return index, True
            time.sleep(1)
        except Exception:
            if retry < 2:
                time.sleep(2)
            continue
    return index, False

def download_m3u8(url, output_dir, filename):
    """ä¸‹è½½M3U8è§†é¢‘"""
    temp_dir = None
    start_time = time.time()
    try:
        # ç¡®ä¿å®‰è£…äº†ä¾èµ–
        if not install_dependencies():
            return
        
        # åˆ†æm3u8å†…å®¹
        analyze_start = time.time()
        segments = analyze_m3u8(url)
        analyze_time = time.time() - analyze_start
        print_step("â±ï¸", f"åˆ†æè€—æ—¶: {analyze_time:.1f}ç§’")
        
        if not segments:
            print_step("âš ï¸", "æ— æ³•åˆ†æè§†é¢‘ç‰‡æ®µï¼Œå°è¯•ç›´æ¥ä¸‹è½½...")
            segments = [{'url': url}]
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = os.path.join(output_dir, "temp")
        os.makedirs(temp_dir, exist_ok=True)
        
        # å‡†å¤‡ä¸‹è½½ä»»åŠ¡
        total_segments = len(segments)
        download_tasks = []
        for i, seg in enumerate(segments):
            seg_path = os.path.join(temp_dir, f"seg_{i:04d}.ts")
            download_tasks.append((seg_path, seg['url'], i, total_segments))
        
        # ä½¿ç”¨çº¿ç¨‹æ± ä¸‹è½½
        download_start = time.time()
        print_step("ğŸš€", f"å¼€å§‹å¤šçº¿ç¨‹ä¸‹è½½ {total_segments} ä¸ªåˆ†ç‰‡...")
        successful_segments = []
        failed_segments = []
        downloaded_count = 0
        
        with ThreadPoolExecutor(max_workers=32) as executor:
            futures = [executor.submit(download_segment, task) for task in download_tasks]
            for future in as_completed(futures):
                index, success = future.result()
                downloaded_count += 1
                if success:
                    successful_segments.append(index)
                else:
                    failed_segments.append(index)
                    print(f"\nâš ï¸ åˆ†ç‰‡ {index+1} ä¸‹è½½å¤±è´¥")
                print(f"\rè¿›åº¦: {downloaded_count}/{total_segments} ({(downloaded_count/total_segments)*100:.1f}%)", end="")
        print("\n")
        
        download_time = time.time() - download_start
        print_step("â±ï¸", f"ä¸‹è½½è€—æ—¶: {download_time:.1f}ç§’")
        
        if not successful_segments:
            raise Exception("æ²¡æœ‰æˆåŠŸä¸‹è½½çš„åˆ†ç‰‡")
        
        if failed_segments:
            print_step("ğŸ“Š", f"æˆåŠŸ: {len(successful_segments)}ä¸ª, å¤±è´¥: {len(failed_segments)}ä¸ª")
        
        # åˆå¹¶åˆ†ç‰‡
        merge_start = time.time()
        print_step("ğŸ“¦", "åˆå¹¶åˆ†ç‰‡...")
        # åˆ›å»ºæ–‡ä»¶åˆ—è¡¨
        list_file = os.path.join(temp_dir, "files.txt")
        with open(list_file, "w") as f:
            for i in sorted(successful_segments):
                f.write(f"file 'seg_{i:04d}.ts'\n")
        
        # ä½¿ç”¨ffmpegåˆå¹¶
        final_path = os.path.join(output_dir, filename)
        merge_cmd = [
            "ffmpeg", "-y",
            "-f", "concat",
            "-safe", "0",
            "-i", list_file,
            "-c", "copy",
            "-bsf:a", "aac_adtstoasc",
            "-movflags", "+faststart",
            final_path
        ]
        
        merge_result = subprocess.run(merge_cmd, capture_output=True, text=True)
        merge_time = time.time() - merge_start
        print_step("â±ï¸", f"åˆå¹¶è€—æ—¶: {merge_time:.1f}ç§’")
        
        if merge_result.returncode != 0:
            print_step("âš ï¸", f"åˆå¹¶å¤±è´¥: {merge_result.stderr}")
            raise Exception("è§†é¢‘åˆå¹¶å¤±è´¥")
        
        # æ£€æŸ¥ç»“æœ
        if os.path.exists(final_path):
            size = os.path.getsize(final_path) / (1024*1024)  # è½¬æ¢ä¸ºMB
            total_time = time.time() - start_time
            print_step(f"ä¸‹è½½å®Œæˆ: {filename} ({size:.1f}MB)")
            print_step(f"æ€»è€—æ—¶: {total_time:.1f}ç§’")
        else:
            raise Exception("è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨")
            
    except Exception as e:
        print_step("âŒ", f"ä¸‹è½½å¤±è´¥: {str(e)}")
        total_time = time.time() - start_time
        print_step("â±ï¸", f"æ€»è€—æ—¶: {total_time:.1f}ç§’")
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if temp_dir and os.path.exists(temp_dir):
            try:
                shutil.rmtree(temp_dir)
            except:
                pass

def extract_m3u8_urls(file_path):
    """ä»æ–‡æœ¬æ–‡ä»¶ä¸­æå–m3u8é“¾æ¥"""
    urls = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            # åŒ¹é…ä»¥.m3u8ç»“å°¾çš„URL
            pattern = r'https?://[^\s<>"\']+?\.m3u8'
            matches = re.findall(pattern, content)
            urls = list(set(matches))  # å»é‡
        print_step("ğŸ”", f"æ‰¾åˆ° {len(urls)} ä¸ªm3u8é“¾æ¥")
        return urls
    except Exception as e:
        print_step("âŒ", f"æå–é“¾æ¥å¤±è´¥: {str(e)}")
        return []

if __name__ == "__main__":
    print_banner()
    
    try:
        # è·å–ç”¨æˆ·è¾“å…¥
        input_path = input("ğŸ”— è¯·è¾“å…¥m3u8é“¾æ¥æˆ–åŒ…å«m3u8é“¾æ¥çš„æ–‡æœ¬æ–‡ä»¶è·¯å¾„: ").strip()
        if not input_path:
            print_step("âŒ", "é”™è¯¯ï¼šè¾“å…¥ä¸èƒ½ä¸ºç©º")
            sys.exit(1)
        
        # è®¾ç½®è¾“å‡ºç›®å½•
        output_dir = os.path.join(os.getcwd(), "output")
        os.makedirs(output_dir, exist_ok=True)
        
        urls_to_download = []
        if input_path.lower().endswith('.m3u8'):
            # ç›´æ¥ä¸‹è½½å•ä¸ªm3u8é“¾æ¥
            urls_to_download = [input_path]
        else:
            # ä»æ–‡ä»¶ä¸­æå–m3u8é“¾æ¥
            if not os.path.exists(input_path):
                print_step("âŒ", "é”™è¯¯ï¼šæ–‡ä»¶ä¸å­˜åœ¨")
                sys.exit(1)
            urls_to_download = extract_m3u8_urls(input_path)
            if not urls_to_download:
                print_step("âŒ", "æœªæ‰¾åˆ°ä»»ä½•m3u8é“¾æ¥")
                sys.exit(1)
        
        print_step("ğŸ“‚", f"è§†é¢‘å°†ä¿å­˜åˆ°: {output_dir}")
        print("=" * 50)
        
        # æ‰¹é‡ä¸‹è½½æ‰€æœ‰é“¾æ¥
        for i, url in enumerate(urls_to_download, 1):
            print(f"\næ­£åœ¨å¤„ç†ç¬¬ {i}/{len(urls_to_download)} ä¸ªæ–‡ä»¶")
            # ä»URLä¸­æå–æ–‡ä»¶å
            filename = os.path.splitext(os.path.basename(urlparse(url).path))[0] + ".mp4"
            print_step("ğŸ“", f"æ–‡ä»¶å: {filename}")
            # å¼€å§‹ä¸‹è½½
            download_m3u8(url, output_dir, filename)
            print("=" * 50)
        
    except KeyboardInterrupt:
        print_step("ğŸ›‘", "ä¸‹è½½å·²å–æ¶ˆ")
    except Exception as e:
        print_step(f"å‘ç”Ÿé”™è¯¯: {str(e)}")
